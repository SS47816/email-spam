{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af2904e-7863-4612-a320-a4919eb4db68",
   "metadata": {},
   "source": [
    "# EE5907/EE5027 Programming Assignment CA1\n",
    "\n",
    "> by: SUN Shuo A0162488U\n",
    "> \n",
    "> \"You may just run the code blocks all the way till the end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f80225-3bcf-48ea-a11d-fe8a385ceb7b",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473df4a-bbdb-4191-9efa-2d6568133b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load mat data\n",
    "mat_data = scipy.io.loadmat('data/spamData.mat')\n",
    "#print(mat_data)\n",
    "x_train = mat_data['Xtrain']\n",
    "y_train = mat_data['ytrain']\n",
    "x_test = mat_data['Xtest']\n",
    "y_test = mat_data['ytest']\n",
    "\n",
    "#x_train = np.array([(1,0), (1,1), (0,0)]).reshape(-1,2)\n",
    "#y_train = np.array([1, 1, 0]).reshape(-1,1)\n",
    "#x_test = np.array([(1,0), (1,0)]).reshape(-1,2)\n",
    "#y_test = np.array([1, 1]).reshape(-1,1)\n",
    "\n",
    "# Check data shapes and types\n",
    "print(\"X train\", type(x_train), \"shape:\", x_train.shape, \"dtype:\", x_train.dtype)\n",
    "print(\"y train\", type(y_train), \"shape:\", y_train.shape, \"dtype:\", y_train.dtype)\n",
    "print(\"X test\", type(x_test), \"shape:\", x_test.shape, \"dtype:\", x_test.dtype)\n",
    "print(\"y test\", type(y_test), \"shape:\", y_test.shape, \"dtype:\", y_test.dtype)\n",
    "\n",
    "# Binarization \n",
    "x_train_bin = (x_train > 0) * 1\n",
    "x_test_bin = (x_test > 0) * 1\n",
    "#print(x_train_bin)\n",
    "#print(x_test_bin)\n",
    "\n",
    "# Log Transform\n",
    "x_train_log = np.log(x_train + 0.1)\n",
    "x_test_log = np.log(x_test + 0.1)\n",
    "#print(x_train_log)\n",
    "#print(x_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ca288-86b1-4ea3-b7f6-254a6b22e0a4",
   "metadata": {},
   "source": [
    "## Q1. Beta-binomial Naive Bayes (24%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a72fd-d423-4c2a-9760-29f9793fe917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(N, N_1, a, b):\n",
    "    \"\"\"\n",
    "    Compute the Beta(`alpha`, `alpha`) distribution\n",
    "    \"\"\"\n",
    "    if (N + a + b) > 0:\n",
    "        return (N_1 + a)/(N + a + b)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def featureLikelihood(X_train, Y_train, j, x_j, c, alpha):\n",
    "    \"\"\"\n",
    "    Compute the feature likelihood term for one (x_test, y_test=c) data point\n",
    "    Class: `c`, Feature: `j`: p(x_test_j| x_i_j, y_test=c)\n",
    "    \"\"\"\n",
    "    N = (Y_train == c).sum()\n",
    "    X_train_j = X_train[:, j].reshape(-1, 1)\n",
    "    N_1 = (X_train_j[Y_train == c] == 1).sum()\n",
    "    #print(\"N:\", N, \"N_1:\", N_1)\n",
    "    \n",
    "    if x_j == 1:\n",
    "        return beta(N, N_1, alpha, alpha)\n",
    "    else:\n",
    "        return 1 - beta(N, N_1, alpha, alpha)\n",
    "\n",
    "def posteriorPredictiveDistribution(X_train, Y_train, X_test, i, c, alpha):\n",
    "    \"\"\"\n",
    "    Compute the posterior predictive distribution of test feature\n",
    "    SUM of log(p(x_test_j | x_i_j, y_test=c))\n",
    "    \"\"\"\n",
    "    p_sum = 0\n",
    "    # For its j-th feature\n",
    "    for j in range(X_test.shape[1]):\n",
    "        p = featureLikelihood(X_train, Y_train, j, X_test[i][j], c, alpha)\n",
    "        if p > 0:\n",
    "            p_sum += np.log(p)\n",
    "        #print(\"Term(\", i, \",\", j, \") is:\", p)\n",
    "            \n",
    "    return p_sum\n",
    "    \n",
    "def betaBinomialNaiveBayes(X_train, Y_train, X_test, alpha):\n",
    "    \"\"\"\n",
    "    Fit a Beta Binomial Naive Bayes Classifier on the `X_train`, `Y_train` data,\n",
    "    and predict the results `Y_pred` with the given `alpha`\n",
    "    \"\"\"\n",
    "    # Class label prior lambda\n",
    "    lambda_ml = (Y_train == 1).sum() / Y_train.shape[0]\n",
    "    #print(\"lambda_ml:\", lambda_ml)\n",
    "    \n",
    "    Y_pred = np.zeros((X_test.shape[0], 1), dtype=int)\n",
    "    # For the i-th test data\n",
    "    for i in range(Y_pred.shape[0]):\n",
    "        P_0 = np.log(1 - lambda_ml) + posteriorPredictiveDistribution(X_train, Y_train, X_test, i, 0, alpha)\n",
    "        P_1 = np.log(lambda_ml) + posteriorPredictiveDistribution(X_train, Y_train, X_test, i, 1, alpha)\n",
    "        #print(P_0)\n",
    "        #print(P_1)\n",
    "        if P_0 < P_1:\n",
    "            Y_pred[i][0] = 1\n",
    "        #print(Y_pred)\n",
    "        #print(\"y predict\", type(Y_pred), \"shape:\", Y_pred.shape, \"dtype:\", Y_pred.dtype)\n",
    "    \n",
    "    return Y_pred\n",
    "\n",
    "def computeErrorRate(X_train, Y_train, X_test, Y_test, alpha):\n",
    "    \"\"\"\n",
    "    Compute the Error Rate based on the `Y_pred` result and the given ground truth `Y_test`, \n",
    "    with a given alpha values\n",
    "    \"\"\"\n",
    "    Y_pred = betaBinomialNaiveBayes(X_train, Y_train, X_test, alpha)\n",
    "    num_error = (Y_pred != Y_test).sum()\n",
    "    \n",
    "    return num_error/Y_test.shape[0]\n",
    "    \n",
    "def compareAlphas(X_train, Y_train, X_test, Y_test, alphas):\n",
    "    \"\"\"\n",
    "    Compute the Error Rate based on the `Y_pred` result and the given ground truth `Y_test`, \n",
    "    with varying alpha values\n",
    "    \"\"\"\n",
    "    error_rates = np.zeros((alphas.shape[0], 1))\n",
    "    for i in tqdm(range(alphas.shape[0])):\n",
    "        error_rates[i] = computeErrorRate(X_train, Y_train, X_test, Y_test, alphas[i])\n",
    "        \n",
    "    return error_rates\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f9d8c-56b2-4a85-994a-3d46b8aed5d3",
   "metadata": {},
   "source": [
    "### Compute and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ee6c4-6832-4d9a-91bf-ebf26097ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experimenting alpha values\n",
    "alphas = np.arange(0, 100.5, 0.5)\n",
    "print(\"Plotting error rates on the training set:\")\n",
    "train_error_rates = compareAlphas(x_train_bin, y_train, x_train_bin, y_train, alphas)\n",
    "print(\"Plotting error rates on the test set:\")\n",
    "test_error_rates = compareAlphas(x_train_bin, y_train, x_test_bin, y_test, alphas)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(alphas, train_error_rates, label='training')\n",
    "line2, = ax.plot(alphas, test_error_rates, dashes=[6, 2], label='test')\n",
    "\n",
    "ax.set(xlabel='alpha', ylabel='error rate', title='Q1. Beta-binomial Naive Bayes')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "fig.savefig(\"pics/q1.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print some results\n",
    "print(\"On the training set, the error rates for α = 1, 10, 100 are respectively:\", \n",
    "      train_error_rates[2], \",\", train_error_rates[20], \",\", train_error_rates[-1])\n",
    "print(\"On the test set, the error rates for α = 1, 10, 100 are respectively:\", \n",
    "      test_error_rates[2], \",\", test_error_rates[20], \",\", test_error_rates[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55940a-bd42-4902-8c60-cd6fdc061cb9",
   "metadata": {},
   "source": [
    "## Q2. Gaussian Naive Bayes (24%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce86e502-b422-434a-8c2d-f7ecf11d4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sigma_sq):\n",
    "    \"\"\"\n",
    "    Compute the gaussian(`mu`, `sigma_sq`) distribution of `x`\n",
    "    \"\"\"\n",
    "    if sigma_sq > 0:\n",
    "        return 1/np.sqrt(2*np.pi*sigma_sq) * np.exp(-0.5*np.power((x - mu), 2)/sigma_sq)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def paramMLEstimate(X_train, Y_train, c):\n",
    "    \"\"\"\n",
    "    Compute the ML estimate of `mean` and `var` for each feature\n",
    "    \"\"\"\n",
    "    row_idxs = []\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        if Y_train[i][0] == c:\n",
    "            row_idxs.append(i)\n",
    "    X_train_c = X_train[np.array(row_idxs), :]\n",
    "    #print(\"X_train_c:\", X_train_c.shape)\n",
    "    mean = np.mean(X_train_c, axis=0)\n",
    "    var = np.var(X_train_c, axis=0)\n",
    "    #print(\"Mean:\", mean[0], \"shape:\", mean.shape)\n",
    "    #print(\"Var:\", var[0], \"shape:\", var.shape)\n",
    "    \n",
    "    return mean, var\n",
    "    \n",
    "def featureLikelihood(x_j, mu, sigma_sq):\n",
    "    \"\"\"\n",
    "    Compute the feature likelihood term for one (x_test, y_test=c) data point\n",
    "    Class: `c`, Feature: `j`: p(x_test_j| x_i_j, y_test=c)\n",
    "    \"\"\"\n",
    "    \n",
    "    return gaussian(x_j, mu, sigma_sq)\n",
    "    \n",
    "def sumFeatureLikelihood(X_test, Means, Vars, i, c):\n",
    "    \"\"\"\n",
    "    Compute the sum of test feature likelihood:\n",
    "    SUM(log(p(x_test_j | x_i_j, y_test=c)))\n",
    "    \"\"\"\n",
    "    p_sum = 0\n",
    "    for j in range(X_test.shape[1]):\n",
    "        p_sum += np.log(featureLikelihood(X_test[i][j], Means[c][j], Vars[c][j]))\n",
    "        \n",
    "    return p_sum\n",
    "\n",
    "def GaussianNaiveBayes(X_train, Y_train, X_test):\n",
    "    \"\"\"\n",
    "    Fit a Beta Binomial Naive Bayes Classifier on the `X_train`, `Y_train` data,\n",
    "    and predict the results `Y_pred` with the given `alpha`\n",
    "    \"\"\"\n",
    "    # Class label prior lambda\n",
    "    lambda_ml = (Y_train == 1).sum() / Y_train.shape[0]\n",
    "    #print(\"lambda_ml:\", lambda_ml)\n",
    "    Means = np.zeros((2, X_train.shape[1]))\n",
    "    Vars = np.zeros((2, X_train.shape[1]))\n",
    "    for i in range(2):\n",
    "        Means[i], Vars[i] = paramMLEstimate(X_train, Y_train, i)\n",
    "    #print(\"Means:\", Means, \"shape:\", Means.shape)\n",
    "    #print(\"Vars:\", Vars, \"shape:\", Vars.shape)\n",
    "    \n",
    "    Y_pred = np.zeros((X_test.shape[0], 1), dtype=int)\n",
    "    # For the i-th test data\n",
    "    for i in range(Y_pred.shape[0]):\n",
    "        P_0 = np.log(1 - lambda_ml) + sumFeatureLikelihood(X_test, Means, Vars, i, 0)\n",
    "        P_1 = np.log(lambda_ml) + sumFeatureLikelihood(X_test, Means, Vars, i, 1)\n",
    "        #print(P_0)\n",
    "        #print(P_1)\n",
    "        if P_0 < P_1:\n",
    "            Y_pred[i][0] = 1\n",
    "            \n",
    "    #print(Y_pred)\n",
    "    #print(\"y predict\", type(Y_pred), \"shape:\", Y_pred.shape, \"dtype:\", Y_pred.dtype)\n",
    "    \n",
    "    return Y_pred\n",
    "\n",
    "def computeErrorRate(X_train, Y_train, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    Compute the Error Rate based on the `Y_pred` result and the given ground truth `Y_test`, \n",
    "    with a given alpha values\n",
    "    \"\"\"\n",
    "    Y_pred = GaussianNaiveBayes(X_train, Y_train, X_test)\n",
    "    num_error = (Y_pred != Y_test).sum()\n",
    "    return num_error/Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e293b-e6ca-467b-ba2c-d5be516e56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the train and test error rate\n",
    "train_error_rate = computeErrorRate(x_train_log, y_train, x_train_log, y_train)\n",
    "test_error_rate = computeErrorRate(x_train_log, y_train, x_test_log, y_test)\n",
    "\n",
    "# Print some results\n",
    "print(\"On the training set, the error rate is:\", train_error_rate)\n",
    "print(\"On the test set, the error rate is:\", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c78a97-7205-431a-8f20-cf8dc110a303",
   "metadata": {},
   "source": [
    "## Q3. Logistic regression (24%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90afebe3-140f-4328-a6be-cb9dfc6cb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid(`x`)\n",
    "    \"\"\"\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def mu(w_, x_):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid(`-w^Tx`)\n",
    "    \"\"\"\n",
    "    return sigmoid(np.transpose(w_).dot(x_))\n",
    "\n",
    "def NLL(w_, X, Y):\n",
    "    \"\"\"\n",
    "    Compute the Negative Log Likelihood, NLL(`w_`)\n",
    "    \"\"\"\n",
    "    nll_sum = 0\n",
    "    for i in range(Y.shape[0]):\n",
    "        mu_i = mu(w_, X[i])\n",
    "        nll_sum += Y[i]*np.log(mu_i) + (1 - Y[i])*np.log(1 - mu_i)\n",
    "        \n",
    "    return -nll_sum\n",
    "\n",
    "def NLLReg(w_, X, Y, _lambda):\n",
    "    \"\"\"\n",
    "    Compute the Negative Log Likelihood with l2 regularization, NLL_reg(`w_`)\n",
    "    \"\"\"\n",
    "    w = np.insert(w_, 0, 0.0)\n",
    "        \n",
    "    return NLL(w, X, Y) + 0.5*_lambda*np.transpose(w_).dot(w_)\n",
    "\n",
    "def hessian(w_, X):\n",
    "    \"\"\"\n",
    "    Compute the Hessian Matrix `H`\n",
    "    \"\"\"\n",
    "    v = []\n",
    "    for i in range(X.shape[0]):\n",
    "        mu_i = mu(w_, X[i])\n",
    "        v.append(mu_i*(1 - mu_i))\n",
    "    S = np.diag(np.array(v))\n",
    "    \n",
    "    return np.transpose(X).dot(S).dot(X)\n",
    "\n",
    "def hessianReg(w_, X, _lambda):\n",
    "    \"\"\"\n",
    "    Compute the Hessian Matrix `H`\n",
    "    \"\"\"\n",
    "    w = np.insert(w_, 0, 0.0)\n",
    "    v = np.ones(w.shape[0])\n",
    "    v[0] = 0.0\n",
    "    \n",
    "    return hessian(w, X) + _lambda*np.diag(v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ca0f5-ee13-4d45-91e5-3e4f510683f8",
   "metadata": {},
   "source": [
    "## Q4. K-Nearest Neighbors (24%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926cd4f9-4256-4b1f-9640-e5a8c1fd16e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
